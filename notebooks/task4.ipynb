{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         TransactionId         BatchId       AccountId       SubscriptionId  \\\n",
      "0  TransactionId_76871   BatchId_36123  AccountId_3957   SubscriptionId_887   \n",
      "1  TransactionId_73770   BatchId_15642  AccountId_4841  SubscriptionId_3829   \n",
      "2  TransactionId_26203   BatchId_53941  AccountId_4229   SubscriptionId_222   \n",
      "3    TransactionId_380  BatchId_102363   AccountId_648  SubscriptionId_2185   \n",
      "4  TransactionId_28195   BatchId_38780  AccountId_4841  SubscriptionId_3829   \n",
      "\n",
      "        CustomerId CurrencyCode  CountryCode    ProviderId     ProductId  \\\n",
      "0  CustomerId_4406          UGX          256  ProviderId_6  ProductId_10   \n",
      "1  CustomerId_4406          UGX          256  ProviderId_4   ProductId_6   \n",
      "2  CustomerId_4683          UGX          256  ProviderId_6   ProductId_1   \n",
      "3   CustomerId_988          UGX          256  ProviderId_1  ProductId_21   \n",
      "4   CustomerId_988          UGX          256  ProviderId_4   ProductId_6   \n",
      "\n",
      "      ProductCategory    ChannelId   Amount  Value  TransactionStartTime  \\\n",
      "0             airtime  ChannelId_3   1000.0   1000  2018-11-15T02:18:49Z   \n",
      "1  financial_services  ChannelId_2    -20.0     20  2018-11-15T02:19:08Z   \n",
      "2             airtime  ChannelId_3    500.0    500  2018-11-15T02:44:21Z   \n",
      "3        utility_bill  ChannelId_3  20000.0  21800  2018-11-15T03:32:55Z   \n",
      "4  financial_services  ChannelId_2   -644.0    644  2018-11-15T03:34:21Z   \n",
      "\n",
      "   PricingStrategy  FraudResult  \n",
      "0                2            0  \n",
      "1                2            0  \n",
      "2                2            0  \n",
      "3                2            0  \n",
      "4                2            0  \n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('../data/data.csv')\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_19349/3946805259.py:18: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['Stability'].fillna(0, inplace=True)  # Replace NaN values for users with only one transaction\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Assuming 'TransactionStartTime' is in datetime format and we already converted it previously\n",
    "df['TransactionStartTime'] = pd.to_datetime(df['TransactionStartTime'])\n",
    "\n",
    "# Recency: Time since the last transaction per user\n",
    "current_date = df['TransactionStartTime'].max()\n",
    "df['Recency'] = df.groupby('AccountId')['TransactionStartTime'].transform(lambda x: (current_date - x.max()).days)\n",
    "\n",
    "# Frequency: Count of transactions per user\n",
    "df['Frequency'] = df.groupby('AccountId')['TransactionId'].transform('count')\n",
    "\n",
    "# Monetary: Total transaction amount per user\n",
    "df['Monetary'] = df.groupby('AccountId')['Amount'].transform('sum')\n",
    "\n",
    "# Stability: Standard deviation of transaction amount per user\n",
    "df['Stability'] = df.groupby('AccountId')['Amount'].transform('std')\n",
    "df['Stability'].fillna(0, inplace=True)  # Replace NaN values for users with only one transaction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate RFMS score\n",
    "# Normalizing the RFMS components to bring them to a similar scale\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "df[['Recency', 'Frequency', 'Monetary', 'Stability']] = scaler.fit_transform(df[['Recency', 'Frequency', 'Monetary', 'Stability']])\n",
    "\n",
    "# Assign a simple weighted RFMS score (weights can be adjusted based on domain knowledge)\n",
    "df['RFMS_Score'] = 0.25 * df['Recency'] + 0.25 * df['Frequency'] + 0.25 * df['Monetary'] + 0.25 * df['Stability']\n",
    "\n",
    "# Classify users: Good (RFMS_Score >= 0.5) and Bad (RFMS_Score < 0.5)\n",
    "df['User_Label'] = np.where(df['RFMS_Score'] >= 0.5, 'Good', 'Bad')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User_Label\n",
      "Bad    95662\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check the distribution of 'User_Label'\n",
    "print(df['User_Label'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User_Label\n",
      "Good    47883\n",
      "Bad     47779\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Calculate the median RFMS score to use as the threshold for classification\n",
    "threshold = df['RFMS_Score'].median()\n",
    "\n",
    "# Classify users again based on the updated threshold\n",
    "df['User_Label'] = np.where(df['RFMS_Score'] >= threshold, 'Good', 'Bad')\n",
    "\n",
    "# Verify the distribution of labels again\n",
    "print(df['User_Label'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         TransactionId         BatchId       AccountId       SubscriptionId  \\\n",
      "0  TransactionId_76871   BatchId_36123  AccountId_3957   SubscriptionId_887   \n",
      "1  TransactionId_73770   BatchId_15642  AccountId_4841  SubscriptionId_3829   \n",
      "2  TransactionId_26203   BatchId_53941  AccountId_4229   SubscriptionId_222   \n",
      "3    TransactionId_380  BatchId_102363   AccountId_648  SubscriptionId_2185   \n",
      "4  TransactionId_28195   BatchId_38780  AccountId_4841  SubscriptionId_3829   \n",
      "\n",
      "        CustomerId CurrencyCode  CountryCode    ProviderId     ProductId  \\\n",
      "0  CustomerId_4406          UGX          256  ProviderId_6  ProductId_10   \n",
      "1  CustomerId_4406          UGX          256  ProviderId_4   ProductId_6   \n",
      "2  CustomerId_4683          UGX          256  ProviderId_6   ProductId_1   \n",
      "3   CustomerId_988          UGX          256  ProviderId_1  ProductId_21   \n",
      "4   CustomerId_988          UGX          256  ProviderId_4   ProductId_6   \n",
      "\n",
      "      ProductCategory  ...   Recency  Frequency  Monetary Stability  \\\n",
      "0             airtime  ...  0.055556   0.002104  0.575014  0.000951   \n",
      "1  financial_services  ...  0.000000   1.000000  0.432651  0.000558   \n",
      "2             airtime  ...  0.900000   0.000032  0.574219  0.000000   \n",
      "3        utility_bill  ...  0.055556   0.000809  0.575494  0.005954   \n",
      "4  financial_services  ...  0.000000   1.000000  0.432651  0.000558   \n",
      "\n",
      "   RFMS_Score  User_Label  WoE  WoE_Frequency_woe  WoE_Monetary_woe  \\\n",
      "0    0.158406           0  NaN                NaN               NaN   \n",
      "1    0.358302           0  NaN                NaN               NaN   \n",
      "2    0.368563           0  NaN                NaN               NaN   \n",
      "3    0.159453           0  NaN                NaN               NaN   \n",
      "4    0.358302           0  NaN                NaN               NaN   \n",
      "\n",
      "   WoE_Stability_woe  \n",
      "0                NaN  \n",
      "1                NaN  \n",
      "2                NaN  \n",
      "3                NaN  \n",
      "4                NaN  \n",
      "\n",
      "[5 rows x 26 columns]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Sample DataFrame creation (replace this with your actual data loading step)\n",
    "# df = pd.read_csv('your_data.csv')\n",
    "\n",
    "# Ensure necessary columns are numeric\n",
    "woe_features = ['Recency', 'Frequency', 'Monetary', 'Stability']\n",
    "target = 'User_Label'\n",
    "\n",
    "for feature in woe_features:\n",
    "    # Convert to numeric, errors='coerce' will turn non-convertible values to NaN\n",
    "    df[feature] = pd.to_numeric(df[feature], errors='coerce')\n",
    "\n",
    "# Convert target to binary if not already\n",
    "df[target] = pd.to_numeric(df[target], errors='coerce')\n",
    "df[target] = df[target].fillna(0).astype(int)  # fill NaN with 0 and ensure binary\n",
    "\n",
    "def calculate_woe(df, feature, target):\n",
    "    df_woe = df[[feature, target]].copy()\n",
    "    df_woe['Total'] = 1\n",
    "\n",
    "    # Group by feature value and calculate Good (0) and Bad (1) counts\n",
    "    grouped = df_woe.groupby(feature).agg({target: ['sum', 'count']})\n",
    "    grouped.columns = ['Bad', 'Total']\n",
    "    grouped['Good'] = grouped['Total'] - grouped['Bad']\n",
    "\n",
    "    # Calculate Distribution of Good and Bad\n",
    "    grouped['Dist_Good'] = grouped['Good'] / grouped['Good'].sum()\n",
    "    grouped['Dist_Bad'] = grouped['Bad'] / grouped['Bad'].sum()\n",
    "\n",
    "    # Handle division by zero and infinite values\n",
    "    grouped['WoE'] = np.where(grouped['Dist_Bad'] == 0, np.inf, np.log(grouped['Dist_Good'] / grouped['Dist_Bad']))\n",
    "\n",
    "    return grouped[['WoE']].reset_index()\n",
    "\n",
    "# Fit the WoE model on features and add to the DataFrame\n",
    "for feature in woe_features:\n",
    "    # Calculate WoE for each feature\n",
    "    woe_values = calculate_woe(df, feature, target)\n",
    "    \n",
    "    # Merge WoE values back to the original DataFrame\n",
    "    df = df.merge(woe_values, on=feature, how='left', suffixes=('', f'_{feature}_woe'))\n",
    "\n",
    "# Check the resulting DataFrame\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed data exported as 'processed_data.csv'.\n"
     ]
    }
   ],
   "source": [
    "# Export the processed DataFrame to a CSV file\n",
    "df.to_csv('processed_data.csv', index=False)\n",
    "print(\"Processed data exported as 'processed_data.csv'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_19349/3097922745.py:19: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  plt.show()\n"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
